import streamlit as st
st.set_page_config(page_title="ë¶€ì‚° ê¸°ì—… RAG", layout="wide")

import os
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document, ChatResult
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema.messages import BaseMessage, HumanMessage, AIMessage
from langchain.chat_models.base import BaseChatModel
from groq import Groq

# âœ… ì»¤ìŠ¤í…€ ChatModel í´ë˜ìŠ¤
class GroqLlamaChat(BaseChatModel):
    groq_api_key: str
    model: str = "meta-llama/llama-4-scout-17b-16e-instruct"
    _client: Groq = None

    def __init__(self, **data):
        super().__init__(**data)
        self._client = Groq(api_key=self.groq_api_key)

    def _call(self, messages, **kwargs):
        formatted = []
        for m in messages:
            if isinstance(m, HumanMessage):
                formatted.append({"role": "user", "content": m.content})
            elif isinstance(m, AIMessage):
                formatted.append({"role": "assistant", "content": m.content})
        response = self._client.chat.completions.create(
            model=self.model,
            messages=formatted,
        )
        return response.choices[0].message.content

    def _generate(self, messages: list[BaseMessage], stop=None, **kwargs) -> ChatResult:
        content = self._call(messages, **kwargs)
        return ChatResult(
            generations=[{"text": content, "message": AIMessage(content=content)}]
        )

    @property
    def _llm_type(self):
        return "groq-llama-4"

    @property
    def _identifying_params(self):
        return {"model": self.model}

# âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”© í•¨ìˆ˜
def load_api_key():
    api_key = st.secrets["general"]["API_KEY"]
    return api_key

def load_template():
    with open("template.txt", "r", encoding="utf-8") as file:
        return file.read()

# âœ… ì´ˆê¸° ì»´í¬ë„ŒíŠ¸ ìºì‹± (1íšŒë§Œ ì‹¤í–‰)
@st.cache_resource
def init_qa_chain():
    api_key = load_api_key()
    template = load_template()

    # ì„ë² ë”© ëª¨ë¸
    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

    # ë²¡í„° ìŠ¤í† ì–´
    vectorstore = FAISS.load_local("busan_db", embedding_model, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    # LLM & í”„ë¡¬í”„íŠ¸
    llm = GroqLlamaChat(groq_api_key=api_key)
    prompt = PromptTemplate.from_template(template)

    # QA ì²´ì¸ ìƒì„±
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True,
    )
    return qa_chain

# âœ… QA ì²´ì¸ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = init_qa_chain()

# âœ… UI êµ¬ì„±
st.title("ğŸš¢ ë¶€ì‚° ì·¨ì—… ìƒë‹´ ì±—ë´‡(JOB MAN)")

query = st.text_input("ğŸ¯ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ) ì‹ ì… ì‚¬ì›ì´ ì²˜ìŒ ë°›ëŠ” ì—°ë´‰ 3000ë§Œì› ì´ìƒ ë˜ëŠ” ì„ ë°• ì œì¡°ì—… íšŒì‚¬ë¥¼ ì¶”ì²œí•´ì¤˜")

# âœ… ë²„íŠ¼ í´ë¦­ ì‹œ, ì²´ì¸ ì‹¤í–‰ë§Œ!
if st.button("ğŸ’¬ ì§ˆë¬¸ ì‹¤í–‰") and query:
    with st.spinner("ğŸ¤– JOB MANì´ ë¶€ì‚° ê¸°ì—… ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
        result = st.session_state.qa_chain.invoke(query)

        st.subheader("âœ… JOB MANì˜ ë‹µë³€")
        st.write(result["result"])

        st.subheader("ğŸ“š ì°¸ê³  ë¬¸ì„œ")
        for i, doc in enumerate(result["source_documents"]):
            with st.expander(f"ë¬¸ì„œ {i+1}"):
                st.write(doc.page_content)


import pandas as pd
import streamlit as st
from geopy.geocoders import GoogleV3
import folium

# Google API í‚¤ ì…ë ¥ (ë°œê¸‰ë°›ì€ API í‚¤ë¡œ êµì²´)
google_api_key = "YOUR_GOOGLE_API_KEY"  # Google API í‚¤ ì…ë ¥

# GoogleV3 Geocoder ì„¤ì •
geolocator = GoogleV3(api_key=google_api_key)

# CSV íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •
df = pd.read_csv("ë¶€ì‚°ê´‘ì—­ì‹œ_ì œì¡°ì—… ê³µì¥ë“±ë¡ í˜„í™©_241231 (1).csv", encoding='cp949')  # ë˜ëŠ” 'euc-kr'

# ìŠ¤íŠ¸ë¦¼ë¦¿ ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©
st.title("íšŒì‚¬ ìœ„ì¹˜ ì§€ë„")

# ì§€ë„ ìƒì„±: ë¶€ì‚°ì˜ ê¸°ë³¸ ì¢Œí‘œë¡œ ì„¤ì •
map = folium.Map(location=[35.1796, 129.0756], zoom_start=12)

# ê° íšŒì‚¬ì— ëŒ€í•´ ì£¼ì†Œë¥¼ ìœ„ë„ì™€ ê²½ë„ë¡œ ë³€í™˜í•˜ê³  ë§ˆì»¤ ì¶”ê°€
for index, row in df.iterrows():
    address = row['ê³µì¥ëŒ€í‘œì£¼ì†Œ(ì§€ë²ˆ)']
    company_name = row['íšŒì‚¬ëª…']
    
    try:
        # ì£¼ì†Œë¥¼ ìœ„ë„, ê²½ë„ë¡œ ë³€í™˜
        location = geolocator.geocode(address)
        
        if location:
            latitude = location.latitude
            longitude = location.longitude
            # ì§€ë„ì— ë§ˆì»¤ ì¶”ê°€
            folium.Marker([latitude, longitude], popup=f"{company_name}\n{address}").add_to(map)
        else:
            st.warning(f"ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {address}")
    
    except Exception as e:
        st.error(f"ì£¼ì†Œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {address} - {str(e)}")

# ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ì§€ë„ë¥¼ í‘œì‹œ
map_html = 'map.html'
map.save(map_html)

# ì§€ë„ HTMLì„ ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ í‘œì‹œ
st.components.v1.html(open(map_html, 'r').read(), height=500)
